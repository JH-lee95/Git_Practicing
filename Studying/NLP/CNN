1.
필터 : 좁은 시야를 가지고 있는 안경 

- 풀레이어에서, 필터(윈도우)를 슬라이드를 이용하여, 각 필터가 본 이미지들에 대하여 값을 도출


2.
Dense layer와 Convolution layer의 가장 큰 차이:
학습 파라미터의 공유 여부
- 덴스레이어는 각각의 노드에 대하여 학습 파라미터들이 모두 다르다.

3.<ConvLayer>
X.shape=(H,W,c)
F.shape=(F,F,c) : F는 학습 파라미터 Wt 
Xwij(X 윈도우) = X[i:F+i,j:F+j,c]
hij(히든 레이어의 ij) = Xwij.dot(F)+b
h.shape=(H`,W`)
W`=(W-F+2P)/S  +  1 (W는 Width)
H`(H-F+2P)/S  +  1  (H는 Height)

h: 새로운 1개 채널의 이미지, activation map
- h의 각 픽셀은 W,b를 공유 한다. 
- h(Dense)에서는 각 피처들이 서로 다른 W,b를 가지고 있다.
- h(Conv)는 h(Dense)에 비에 W,b의 개수가 적다.
- 학습 시간이 빠르다.

4.
cnn에서 필터의 역할? : 디테일에 집중할 수 있음
여러개의 F를 사용하면, activation maps 생성 
-각 Filter는 이미지에서 특징적인 패턴을 추출
- 필터의 출력 채널은 항상 입력채널과 같다.
ex) 음성처리에서는, a필터는 베이스에, b필터는 하모니에 c필터는 고음에 집중할 수 잇음
ex)  자연어처리에서는 a필터는 조사 , b 필터는 명사 등등


패딩은 : 원래 이미지 사이즈를 복원해주는 효과가 있다. 


- Low-level 필터에서 High-level 필터로 갈수록 더 형태를 찾아감
ex) low-level에서는 조도 등을 감지 하고 high-level에서는 눈,귀,코 등을 감지



1conv
(32,32,3) == 10 (5,5,3) => (28,28,10)
학습 w의 수 => 10 * 5 * 5 * 3
학습 b의 수 => 10 

2conv
(32,32,3) == 10 (3,3,3) => (30,30,10)
학습 W,b의 수 N1: 10*3*3*3 + 10
(30,30,10) == 10 (3,3,10) ==> (28,28,10)
학습 W,b의 수 N2: 10*3*3*10 + 10
N1+N2=10*3*3*(3+10) + 20




VGGNet의 등장 이후 거의 3*3 필터를 많이 쓴다.
또는 (1*3  or 3*1)

3*3 필터는 5*5 필터에 비해
- 한 layer 더 학습하면서
- 학습 파라미터의 수는 더 적다. 
