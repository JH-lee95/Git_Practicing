{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오차 수정하기 : 경사하강법\n",
    "\n",
    "1. 기울기 w에 대한 함수가 2차함수 이므로, 기울기 w를 무한대로 키워도 오차가 무한대로 커지고, 반대로 기울기 w를 무한대로 낮춰도 오차가 무한대로 커짐 \n",
    "\n",
    "2. 기울기 w를 미분하여, 미분값이 0인경우를 찾는다. (오차가 최소값인 경우). \n",
    "\n",
    "\n",
    "3. 학습률(Learning Rate) : 얼마나 이동시킬지 정해주는 것 - 최소값을 찾지 못해, 이동이 필요할 경우, 학습률을 적절하게 정하지 못할 경우 오차가 발산을 하거나, 특정 구간을 계속해서 반복할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[2,81],[4,93],[6,91],[8,97]]\n",
    "x_data=[x_row[0] for x_row in data]\n",
    "y_data=[y_row[1] for y_row in data]\n",
    "\n",
    "a=tf.Variable(tf.random_uniform([1],0,10,dtype=tf.float64,seed=0)) #tf.random_uniform(shape,minval,maxval,dtype,seed)\n",
    "b=tf.Variable(tf.random_uniform([1],0,100,dtype=tf.float64,seed=0))\n",
    "\n",
    "y=a*x_data+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 4, 6, 8], [81, 93, 91, 97])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, RMSE=30.2139, 기울기 a : 7.5235, y 절편 b : 80.5984\n",
      "Epoch : 100, RMSE=2.8860, 기울기 a : 2.2299, y 절편 b : 79.4181\n",
      "Epoch : 200, RMSE=2.8826, 기울기 a : 2.2601, y 절편 b : 79.2379\n",
      "Epoch : 300, RMSE=2.8815, 기울기 a : 2.2773, y 절편 b : 79.1353\n",
      "Epoch : 400, RMSE=2.8811, 기울기 a : 2.2871, y 절편 b : 79.0770\n",
      "Epoch : 500, RMSE=2.8810, 기울기 a : 2.2927, y 절편 b : 79.0438\n",
      "Epoch : 600, RMSE=2.8810, 기울기 a : 2.2958, y 절편 b : 79.0249\n",
      "Epoch : 700, RMSE=2.8810, 기울기 a : 2.2976, y 절편 b : 79.0142\n",
      "Epoch : 800, RMSE=2.8810, 기울기 a : 2.2987, y 절편 b : 79.0081\n",
      "Epoch : 900, RMSE=2.8810, 기울기 a : 2.2992, y 절편 b : 79.0046\n",
      "Epoch : 1000, RMSE=2.8810, 기울기 a : 2.2996, y 절편 b : 79.0026\n",
      "Epoch : 1100, RMSE=2.8810, 기울기 a : 2.2998, y 절편 b : 79.0015\n",
      "Epoch : 1200, RMSE=2.8810, 기울기 a : 2.2999, y 절편 b : 79.0008\n",
      "Epoch : 1300, RMSE=2.8810, 기울기 a : 2.2999, y 절편 b : 79.0005\n",
      "Epoch : 1400, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0003\n",
      "Epoch : 1500, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0002\n",
      "Epoch : 1600, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0001\n",
      "Epoch : 1700, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0001\n",
      "Epoch : 1800, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0000\n",
      "Epoch : 1900, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0000\n",
      "Epoch : 2000, RMSE=2.8810, 기울기 a : 2.3000, y 절편 b : 79.0000\n"
     ]
    }
   ],
   "source": [
    "#텐서플로 rmse함수\n",
    "rmse=tf.sqrt(tf.reduce_mean(tf.square(y-y_data)))  #얘도 텐서 (결과값이아님)\n",
    "\n",
    "#reduce_mean : 전체 데이터의 합의 평균을 구하면서 그 값을 스칼라로 배출(차원축소)\n",
    "# mse : sum((y-(y-data))^2)/n 을 그대로 코드로 표현한것임\n",
    "\n",
    "#학습률 \n",
    "learning_rate=0.1\n",
    "\n",
    "#경사하강법을 통해 RMSE값을 최소로 하는 값을 찾기 위해 학습을 시킴\n",
    "gradient_descent=tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(rmse)\n",
    "\n",
    "\n",
    "#optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1) \n",
    "#train=optimizer.minimize(rmse)\n",
    "\n",
    "\n",
    "#텐서플로를 이용한 학습\n",
    "with tf.Session() as sess:\n",
    "    #변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #2001번 실행\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        #100번 마다 결과 출력\n",
    "        if step % 100==0:\n",
    "            print(\"Epoch : %.f, RMSE=%.04f, 기울기 a : %.4f, y 절편 b : %.4f\" %(step,sess.run(rmse),sess.run(a),sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *학습률\n",
    "학습률이 너무 크면 손실함수 값이 줄어들지 않고 오히려 더 커지는 오버슈팅(over shooting) 현상이 발생한다.\n",
    "반면에 학습률이 너무 작으면, 수렴이 늦어지고, 지역 최소점에 걸릴 수 있다.\n",
    "\n",
    "학습률은 특별한 공식으로 계산하는 것이 아니라, 경험적으로 (시행착오를 통해) 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
