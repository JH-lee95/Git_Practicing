{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"sonar.csv\",header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.values\n",
    "\n",
    "X=dataset[:,0:60].astype(float)\n",
    "Y_obj=dataset[:,[60]]\n",
    "\n",
    "e=LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y=e.transform(Y_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(24,input_dim=60,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200,batch_size=5)\n",
    "print(\"Accuracy : %.4f\" % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 분리 후 다시 피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\tf_v2\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "dataset=df.values\n",
    "\n",
    "X=dataset[:,0:60].astype(float)\n",
    "Y_obj=dataset[:,[60]]\n",
    "\n",
    "e=LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y=e.transform(Y_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(24,input_dim=60,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=130,batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : %.4f\" % (model.evaluate(X_test,Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장과 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1288 - accuracy: 0.8438WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0009s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 964us/step - loss: 0.1303 - accuracy: 0.8254\n",
      "Accuracy : 0.8254\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : %.4f\" % (model.evaluate(X_test,Y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K겹 교차 검증\n",
    "\n",
    " - 적은 데이터셋을 최대한 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.values\n",
    "\n",
    "X=dataset[:,0:60].astype(float)\n",
    "Y_obj=dataset[:,[60]]\n",
    "\n",
    "e=LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y=e.transform(Y_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold=10 #10개의 파일로 쪼갬\n",
    "skf=StratifiedKFold(n_splits=n_fold,shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  20\n",
      "  21  23  24  25  27  28  29  30  31  32  33  34  35  36  37  38  39  41\n",
      "  42  43  45  46  47  48  50  51  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  92  93  94  95  96  97  98  99\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 118 120\n",
      " 121 123 124 125 126 127 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 142 143 144 145 146 147 148 149 150 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 198 199\n",
      " 200 201 202 203 205 206 207] [  2  14  19  22  26  40  44  49  52  91 100 117 119 122 128 141 151 191\n",
      " 196 197 204]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#SKF.SPLIT(X,Y)는 해당 데이터의 인덱스의 넘파이 어레이를 만들어냄\n",
    "\n",
    "\n",
    "for t1,t2 in skf.split(X,Y):\n",
    "    print(t1,t2)\n",
    "    print(type(t1),type(t2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 646us/step - loss: 0.2500 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 648us/step - loss: 0.2393 - accuracy: 0.6417\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.2307 - accuracy: 0.6791\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 703us/step - loss: 0.2226 - accuracy: 0.7326\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 697us/step - loss: 0.2114 - accuracy: 0.7326\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.2016 - accuracy: 0.7487\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.1866 - accuracy: 0.7754\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.1739 - accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.1621 - accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.1530 - accuracy: 0.8289\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.1463 - accuracy: 0.8289\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 668us/step - loss: 0.1442 - accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 698us/step - loss: 0.1377 - accuracy: 0.8342\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 696us/step - loss: 0.1300 - accuracy: 0.8342\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 672us/step - loss: 0.1209 - accuracy: 0.8610\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 716us/step - loss: 0.1165 - accuracy: 0.8663\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 724us/step - loss: 0.1127 - accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 664us/step - loss: 0.1110 - accuracy: 0.8717\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 703us/step - loss: 0.1124 - accuracy: 0.8075\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 701us/step - loss: 0.1086 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 678us/step - loss: 0.1056 - accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 688us/step - loss: 0.0988 - accuracy: 0.8770\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0974 - accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0970 - accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0908 - accuracy: 0.9037\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0915 - accuracy: 0.8770\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 700us/step - loss: 0.0853 - accuracy: 0.8984\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.0878 - accuracy: 0.9037\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0842 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 713us/step - loss: 0.0896 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 688us/step - loss: 0.0824 - accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0801 - accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 710us/step - loss: 0.0753 - accuracy: 0.9305\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 711us/step - loss: 0.0763 - accuracy: 0.9251\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 664us/step - loss: 0.0771 - accuracy: 0.8984\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0690 - accuracy: 0.9305\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.0718 - accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.0721 - accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 729us/step - loss: 0.0686 - accuracy: 0.9305\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 662us/step - loss: 0.0650 - accuracy: 0.9144\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 698us/step - loss: 0.0636 - accuracy: 0.9465\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 691us/step - loss: 0.0629 - accuracy: 0.9358\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 704us/step - loss: 0.0612 - accuracy: 0.9465\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 689us/step - loss: 0.0616 - accuracy: 0.9305\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 722us/step - loss: 0.0597 - accuracy: 0.9412\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 708us/step - loss: 0.0616 - accuracy: 0.9251\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 647us/step - loss: 0.0559 - accuracy: 0.9679\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0537 - accuracy: 0.9412\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0509 - accuracy: 0.9572\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 703us/step - loss: 0.0511 - accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 646us/step - loss: 0.0492 - accuracy: 0.9519\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 713us/step - loss: 0.0501 - accuracy: 0.9572\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 708us/step - loss: 0.0471 - accuracy: 0.9733\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0478 - accuracy: 0.9572\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 708us/step - loss: 0.0436 - accuracy: 0.9786\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 706us/step - loss: 0.0472 - accuracy: 0.9572\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 680us/step - loss: 0.0418 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 685us/step - loss: 0.0404 - accuracy: 0.9786\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0400 - accuracy: 0.9840\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 689us/step - loss: 0.0374 - accuracy: 0.9733\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.0380 - accuracy: 0.9786\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0371 - accuracy: 0.9733\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 639us/step - loss: 0.0354 - accuracy: 0.9786\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 685us/step - loss: 0.0357 - accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0357 - accuracy: 0.9840\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.0317 - accuracy: 0.9840\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0329 - accuracy: 0.9840\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0293 - accuracy: 0.9893\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 693us/step - loss: 0.0306 - accuracy: 0.9840\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0286 - accuracy: 0.9840\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.0297 - accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 635us/step - loss: 0.0276 - accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 725us/step - loss: 0.0262 - accuracy: 0.9893\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 696us/step - loss: 0.0253 - accuracy: 0.9893\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 648us/step - loss: 0.0263 - accuracy: 0.9840\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 692us/step - loss: 0.0228 - accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.0207 - accuracy: 0.9893\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 713us/step - loss: 0.0206 - accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.0202 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 654us/step - loss: 0.0192 - accuracy: 0.9947\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 688us/step - loss: 0.0204 - accuracy: 0.9840\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 704us/step - loss: 0.0172 - accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0187 - accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 704us/step - loss: 0.0187 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0152 - accuracy: 0.9947\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.0177 - accuracy: 0.9893\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 709us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 659us/step - loss: 0.0153 - accuracy: 0.9893\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0133 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 653us/step - loss: 0.0118 - accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0144 - accuracy: 0.9947\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0119 - accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 711us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.0116 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 659us/step - loss: 0.0114 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.2532 - accuracy: 0.4118\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 544us/step - loss: 0.2454 - accuracy: 0.5615\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.2407 - accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.2348 - accuracy: 0.6043\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.2244 - accuracy: 0.5668\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.2127 - accuracy: 0.7166\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 585us/step - loss: 0.2015 - accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.1870 - accuracy: 0.7380\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 553us/step - loss: 0.1746 - accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 553us/step - loss: 0.1659 - accuracy: 0.7807\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 529us/step - loss: 0.1601 - accuracy: 0.7861\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 567us/step - loss: 0.1583 - accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.1504 - accuracy: 0.8235\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 574us/step - loss: 0.1433 - accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.1357 - accuracy: 0.8449\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 568us/step - loss: 0.1307 - accuracy: 0.8610\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 557us/step - loss: 0.1266 - accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 595us/step - loss: 0.1243 - accuracy: 0.8663\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 568us/step - loss: 0.1256 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 711us/step - loss: 0.1240 - accuracy: 0.8556\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 567us/step - loss: 0.1192 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 565us/step - loss: 0.1124 - accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 562us/step - loss: 0.1069 - accuracy: 0.8663\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 586us/step - loss: 0.1041 - accuracy: 0.8717\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.1038 - accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.0964 - accuracy: 0.8930\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.0976 - accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0957 - accuracy: 0.8824\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0880 - accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 571us/step - loss: 0.0922 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.0863 - accuracy: 0.8984\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0834 - accuracy: 0.9144\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 516us/step - loss: 0.0770 - accuracy: 0.9412\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 558us/step - loss: 0.0755 - accuracy: 0.9198\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 568us/step - loss: 0.0825 - accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.0686 - accuracy: 0.9198\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 538us/step - loss: 0.0688 - accuracy: 0.9412\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 548us/step - loss: 0.0682 - accuracy: 0.9251\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0679 - accuracy: 0.9198\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0627 - accuracy: 0.9572\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0651 - accuracy: 0.9305\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0623 - accuracy: 0.9198\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 564us/step - loss: 0.0560 - accuracy: 0.9465\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0611 - accuracy: 0.9305\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0558 - accuracy: 0.9412\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.0571 - accuracy: 0.9519\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0530 - accuracy: 0.9679\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 546us/step - loss: 0.0499 - accuracy: 0.9626\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 532us/step - loss: 0.0495 - accuracy: 0.9733\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0495 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 535us/step - loss: 0.0509 - accuracy: 0.9572\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0464 - accuracy: 0.9733\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 547us/step - loss: 0.0470 - accuracy: 0.9679\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0476 - accuracy: 0.9679\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0431 - accuracy: 0.9626\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0410 - accuracy: 0.9733\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0407 - accuracy: 0.9679\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 545us/step - loss: 0.0390 - accuracy: 0.9733\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 526us/step - loss: 0.0372 - accuracy: 0.9786\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 553us/step - loss: 0.0345 - accuracy: 0.9786\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0350 - accuracy: 0.9786\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 544us/step - loss: 0.0323 - accuracy: 0.9893\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0347 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0350 - accuracy: 0.9786\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.0289 - accuracy: 0.9893\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0309 - accuracy: 0.9786\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0316 - accuracy: 0.9840\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 559us/step - loss: 0.0314 - accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 536us/step - loss: 0.0271 - accuracy: 0.9947\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 530us/step - loss: 0.0269 - accuracy: 0.9840\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 532us/step - loss: 0.0262 - accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 547us/step - loss: 0.0265 - accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.0237 - accuracy: 0.9840\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 530us/step - loss: 0.0224 - accuracy: 0.9893\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.0211 - accuracy: 0.9893\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0233 - accuracy: 0.9947\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0202 - accuracy: 0.9947\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 522us/step - loss: 0.0231 - accuracy: 0.9840\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.0185 - accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0198 - accuracy: 0.9947\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0234 - accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0170 - accuracy: 0.9947\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 518us/step - loss: 0.0167 - accuracy: 0.9947\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 548us/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 563us/step - loss: 0.0147 - accuracy: 0.9947\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 533us/step - loss: 0.0223 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0159 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 544us/step - loss: 0.0121 - accuracy: 0.9947\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 527us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0112 - accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 557us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0107 - accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 546us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 539us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.2449 - accuracy: 0.4920\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 636us/step - loss: 0.2379 - accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 661us/step - loss: 0.2316 - accuracy: 0.6417\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.2238 - accuracy: 0.6845\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 560us/step - loss: 0.2143 - accuracy: 0.7433\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 586us/step - loss: 0.2030 - accuracy: 0.7166\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1844 - accuracy: 0.7540\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 633us/step - loss: 0.1730 - accuracy: 0.7701\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.1639 - accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 595us/step - loss: 0.1568 - accuracy: 0.8021\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.1543 - accuracy: 0.8021\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 618us/step - loss: 0.1508 - accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.1512 - accuracy: 0.7914\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.1427 - accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.1345 - accuracy: 0.8235\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 595us/step - loss: 0.1326 - accuracy: 0.8128\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.1297 - accuracy: 0.8342\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.1245 - accuracy: 0.8396\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.1241 - accuracy: 0.8289\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 611us/step - loss: 0.1241 - accuracy: 0.8289\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 595us/step - loss: 0.1219 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.1124 - accuracy: 0.8717\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 508us/step - loss: 0.1091 - accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 521us/step - loss: 0.1098 - accuracy: 0.8503\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.1033 - accuracy: 0.8877\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.1086 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.1000 - accuracy: 0.8877\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0964 - accuracy: 0.8877\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.0938 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0941 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 584us/step - loss: 0.0921 - accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 598us/step - loss: 0.0900 - accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0859 - accuracy: 0.8930\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0843 - accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 623us/step - loss: 0.0877 - accuracy: 0.9198\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.0808 - accuracy: 0.9037\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 607us/step - loss: 0.0822 - accuracy: 0.8984\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 538us/step - loss: 0.0899 - accuracy: 0.8717\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 567us/step - loss: 0.0785 - accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0729 - accuracy: 0.9305\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0730 - accuracy: 0.9251\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 510us/step - loss: 0.0701 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 531us/step - loss: 0.0696 - accuracy: 0.9198\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 494us/step - loss: 0.0697 - accuracy: 0.9251\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0674 - accuracy: 0.9358\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 586us/step - loss: 0.0730 - accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.0685 - accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.0654 - accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0622 - accuracy: 0.9412\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.0611 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 614us/step - loss: 0.0599 - accuracy: 0.9519\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.0595 - accuracy: 0.9465\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.0591 - accuracy: 0.9358\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0566 - accuracy: 0.9465\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0548 - accuracy: 0.9519\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0533 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0511 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.0555 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 624us/step - loss: 0.0497 - accuracy: 0.9626\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0531 - accuracy: 0.9412\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 643us/step - loss: 0.0475 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.0472 - accuracy: 0.9626\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 622us/step - loss: 0.0478 - accuracy: 0.9572\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 609us/step - loss: 0.0480 - accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 641us/step - loss: 0.0460 - accuracy: 0.9572\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.0429 - accuracy: 0.9626\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 625us/step - loss: 0.0421 - accuracy: 0.9733\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.0410 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 645us/step - loss: 0.0415 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 589us/step - loss: 0.0415 - accuracy: 0.9572\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.0387 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 598us/step - loss: 0.0447 - accuracy: 0.9679\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0404 - accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.0361 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.0368 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.0374 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 611us/step - loss: 0.0372 - accuracy: 0.9572\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 614us/step - loss: 0.0329 - accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 624us/step - loss: 0.0334 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0316 - accuracy: 0.9733\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0334 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 532us/step - loss: 0.0317 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0320 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0306 - accuracy: 0.9733\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 511us/step - loss: 0.0302 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.0375 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 514us/step - loss: 0.0286 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 521us/step - loss: 0.0270 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 518us/step - loss: 0.0289 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.0289 - accuracy: 0.9786\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 524us/step - loss: 0.0263 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0261 - accuracy: 0.9786\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0268 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 494us/step - loss: 0.0260 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0245 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 498us/step - loss: 0.0222 - accuracy: 0.9840\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 420us/step - loss: 0.0229 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 521us/step - loss: 0.0250 - accuracy: 0.9786\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.0213 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 530us/step - loss: 0.0214 - accuracy: 0.9840\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF18C7A558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.2401 - accuracy: 0.5561\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.2309 - accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.2205 - accuracy: 0.6524\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.2103 - accuracy: 0.7059\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.2017 - accuracy: 0.6631\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1929 - accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.1818 - accuracy: 0.7701\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.1721 - accuracy: 0.8289\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 592us/step - loss: 0.1643 - accuracy: 0.8128\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 568us/step - loss: 0.1573 - accuracy: 0.8503\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 603us/step - loss: 0.1530 - accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.1552 - accuracy: 0.7968\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.1534 - accuracy: 0.7861\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 571us/step - loss: 0.1429 - accuracy: 0.8182\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 634us/step - loss: 0.1350 - accuracy: 0.8396\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.1324 - accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 610us/step - loss: 0.1316 - accuracy: 0.8289\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.1287 - accuracy: 0.8449\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.1227 - accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.1294 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 635us/step - loss: 0.1235 - accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.1170 - accuracy: 0.8342\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.1132 - accuracy: 0.8556\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.1153 - accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 594us/step - loss: 0.1153 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 586us/step - loss: 0.1071 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.1090 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.1072 - accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.1036 - accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.1174 - accuracy: 0.8503\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.1074 - accuracy: 0.8663\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 623us/step - loss: 0.0980 - accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0940 - accuracy: 0.8984\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 594us/step - loss: 0.0917 - accuracy: 0.8877\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0958 - accuracy: 0.8770\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0842 - accuracy: 0.8930\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.0877 - accuracy: 0.8984\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 587us/step - loss: 0.0855 - accuracy: 0.8984\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0846 - accuracy: 0.9037\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0794 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0820 - accuracy: 0.9091\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.0800 - accuracy: 0.9037\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 590us/step - loss: 0.0780 - accuracy: 0.9198\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0793 - accuracy: 0.8984\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.0746 - accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0759 - accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 649us/step - loss: 0.0749 - accuracy: 0.8824\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.0736 - accuracy: 0.9037\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.0703 - accuracy: 0.9251\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.0692 - accuracy: 0.9198\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.0654 - accuracy: 0.9251\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0640 - accuracy: 0.9251\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 664us/step - loss: 0.0628 - accuracy: 0.9198\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 653us/step - loss: 0.0624 - accuracy: 0.9412\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 664us/step - loss: 0.0585 - accuracy: 0.9358\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 666us/step - loss: 0.0595 - accuracy: 0.9251\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 708us/step - loss: 0.0536 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0580 - accuracy: 0.9519\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 658us/step - loss: 0.0571 - accuracy: 0.9519\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0518 - accuracy: 0.9626\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0526 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0570 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0564 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 633us/step - loss: 0.0486 - accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 698us/step - loss: 0.0514 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 684us/step - loss: 0.0459 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 646us/step - loss: 0.0431 - accuracy: 0.9679\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0421 - accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0412 - accuracy: 0.9519\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 661us/step - loss: 0.0477 - accuracy: 0.9465\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.0427 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 686us/step - loss: 0.0403 - accuracy: 0.9679\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0375 - accuracy: 0.9786\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 632us/step - loss: 0.0371 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 645us/step - loss: 0.0369 - accuracy: 0.9786\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.0345 - accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0342 - accuracy: 0.9786\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 694us/step - loss: 0.0347 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0315 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 678us/step - loss: 0.0310 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.0337 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0294 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0294 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 672us/step - loss: 0.0293 - accuracy: 0.9733\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 696us/step - loss: 0.0303 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 686us/step - loss: 0.0287 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0278 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 648us/step - loss: 0.0258 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 688us/step - loss: 0.0317 - accuracy: 0.9679\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 690us/step - loss: 0.0264 - accuracy: 0.9786\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 680us/step - loss: 0.0300 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 653us/step - loss: 0.0338 - accuracy: 0.9626\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 684us/step - loss: 0.0228 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0227 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0205 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0201 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0200 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 709us/step - loss: 0.0184 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0195 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.0184 - accuracy: 0.9786\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF1907F4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0632 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.2429 - accuracy: 0.5080\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.2277 - accuracy: 0.6043\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.2135 - accuracy: 0.7380\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.2006 - accuracy: 0.7701\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 469us/step - loss: 0.1895 - accuracy: 0.7219\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 445us/step - loss: 0.1773 - accuracy: 0.7487\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.1680 - accuracy: 0.7968\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 548us/step - loss: 0.1583 - accuracy: 0.8289\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.1499 - accuracy: 0.8342\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.1436 - accuracy: 0.8342\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 591us/step - loss: 0.1412 - accuracy: 0.8289\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 568us/step - loss: 0.1420 - accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.1366 - accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 539us/step - loss: 0.1278 - accuracy: 0.8396\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1255 - accuracy: 0.8717\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 624us/step - loss: 0.1212 - accuracy: 0.8663\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.1224 - accuracy: 0.8556\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.1155 - accuracy: 0.8556\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1175 - accuracy: 0.8449\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.1266 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1127 - accuracy: 0.8717\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.1071 - accuracy: 0.8824\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.1023 - accuracy: 0.8824\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.1068 - accuracy: 0.8503\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.1051 - accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0975 - accuracy: 0.8930\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 575us/step - loss: 0.1003 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 633us/step - loss: 0.0942 - accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.0905 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0904 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0866 - accuracy: 0.9037\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 531us/step - loss: 0.0857 - accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0844 - accuracy: 0.9144\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.0847 - accuracy: 0.9037\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0842 - accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 540us/step - loss: 0.0770 - accuracy: 0.9037\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0800 - accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0754 - accuracy: 0.9198\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0766 - accuracy: 0.9305\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0721 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0757 - accuracy: 0.9251\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0720 - accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 558us/step - loss: 0.0787 - accuracy: 0.8984\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0712 - accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0649 - accuracy: 0.9305\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 536us/step - loss: 0.0670 - accuracy: 0.9251\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 574us/step - loss: 0.0681 - accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0624 - accuracy: 0.9412\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.0585 - accuracy: 0.9572\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0581 - accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0572 - accuracy: 0.9198\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0584 - accuracy: 0.9305\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0607 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0566 - accuracy: 0.9519\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 571us/step - loss: 0.0562 - accuracy: 0.9519\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 535us/step - loss: 0.0530 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 527us/step - loss: 0.0521 - accuracy: 0.9519\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0514 - accuracy: 0.9465\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.0492 - accuracy: 0.9519\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 543us/step - loss: 0.0510 - accuracy: 0.9465\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0476 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0474 - accuracy: 0.9465\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 577us/step - loss: 0.0477 - accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0447 - accuracy: 0.9626\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.0423 - accuracy: 0.9572\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0414 - accuracy: 0.9626\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.0431 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.0394 - accuracy: 0.9679\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.0403 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0461 - accuracy: 0.9412\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 585us/step - loss: 0.0400 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 562us/step - loss: 0.0394 - accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0377 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 554us/step - loss: 0.0350 - accuracy: 0.9786\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 550us/step - loss: 0.0341 - accuracy: 0.9786\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0360 - accuracy: 0.9733\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 554us/step - loss: 0.0350 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 571us/step - loss: 0.0320 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.0318 - accuracy: 0.9786\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0324 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0342 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.0325 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 546us/step - loss: 0.0286 - accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.0291 - accuracy: 0.9840\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 558us/step - loss: 0.0279 - accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.0321 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 542us/step - loss: 0.0311 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 535us/step - loss: 0.0274 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 567us/step - loss: 0.0268 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.0271 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0264 - accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 509us/step - loss: 0.0305 - accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0265 - accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0242 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0240 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0211 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.0247 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0259 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.0229 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 573us/step - loss: 0.0205 - accuracy: 0.9840\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF1907F0D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1194 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.2548 - accuracy: 0.4492\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.2437 - accuracy: 0.5882\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.2372 - accuracy: 0.6738\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 627us/step - loss: 0.2294 - accuracy: 0.6417\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.2194 - accuracy: 0.6524\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 654us/step - loss: 0.2123 - accuracy: 0.6845\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.2023 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.1912 - accuracy: 0.7647\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 610us/step - loss: 0.1822 - accuracy: 0.7647\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.1741 - accuracy: 0.7861\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 618us/step - loss: 0.1704 - accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.1667 - accuracy: 0.7861\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.1622 - accuracy: 0.8075\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 627us/step - loss: 0.1530 - accuracy: 0.7914\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.1476 - accuracy: 0.8289\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.1430 - accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 609us/step - loss: 0.1386 - accuracy: 0.8128\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1382 - accuracy: 0.8449\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 622us/step - loss: 0.1350 - accuracy: 0.8235\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.1403 - accuracy: 0.8075\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 596us/step - loss: 0.1361 - accuracy: 0.8075\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.1279 - accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.1238 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.1270 - accuracy: 0.8289\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.1191 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.1238 - accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.1181 - accuracy: 0.8342\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.1211 - accuracy: 0.8342\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 585us/step - loss: 0.1144 - accuracy: 0.8342\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 625us/step - loss: 0.1179 - accuracy: 0.8449\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.1161 - accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.1097 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.1080 - accuracy: 0.8556\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1066 - accuracy: 0.8610\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 630us/step - loss: 0.1092 - accuracy: 0.8610\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.1030 - accuracy: 0.8770\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.1078 - accuracy: 0.8663\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.1022 - accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 587us/step - loss: 0.0975 - accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0951 - accuracy: 0.8770\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.00 - 0s 569us/step - loss: 0.1004 - accuracy: 0.8717\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.0924 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.0962 - accuracy: 0.8717\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.0911 - accuracy: 0.8610\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.0910 - accuracy: 0.8877\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.0906 - accuracy: 0.8930\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0889 - accuracy: 0.9037\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.0839 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 618us/step - loss: 0.0823 - accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0797 - accuracy: 0.9037\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.0895 - accuracy: 0.8824\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0813 - accuracy: 0.8930\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0796 - accuracy: 0.9305\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.0835 - accuracy: 0.9037\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 594us/step - loss: 0.0782 - accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0765 - accuracy: 0.9144\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.0722 - accuracy: 0.9358\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0725 - accuracy: 0.9251\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.0745 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 641us/step - loss: 0.0733 - accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.0716 - accuracy: 0.9198\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0691 - accuracy: 0.9358\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0665 - accuracy: 0.9251\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 592us/step - loss: 0.0630 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 609us/step - loss: 0.0654 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.0623 - accuracy: 0.9305\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 625us/step - loss: 0.0652 - accuracy: 0.9305\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.0629 - accuracy: 0.9358\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0658 - accuracy: 0.9358\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 553us/step - loss: 0.0636 - accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 548us/step - loss: 0.0600 - accuracy: 0.9412\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 517us/step - loss: 0.0558 - accuracy: 0.9519\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0587 - accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0555 - accuracy: 0.9358\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.0541 - accuracy: 0.9465\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.0556 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0553 - accuracy: 0.9519\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0513 - accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 635us/step - loss: 0.0528 - accuracy: 0.9626\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.0497 - accuracy: 0.9572\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0500 - accuracy: 0.9572\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.0468 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 618us/step - loss: 0.0461 - accuracy: 0.9626\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0467 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 609us/step - loss: 0.0489 - accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.0523 - accuracy: 0.9519\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0459 - accuracy: 0.9572\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 506us/step - loss: 0.0485 - accuracy: 0.9519\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 527us/step - loss: 0.0504 - accuracy: 0.9465\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0485 - accuracy: 0.9465\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0432 - accuracy: 0.9626\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 594us/step - loss: 0.0417 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0372 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 590us/step - loss: 0.0384 - accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.0361 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.0362 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0377 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0338 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 616us/step - loss: 0.0328 - accuracy: 0.9786\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.0317 - accuracy: 0.9786\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF171F4558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1477 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.2476 - accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.2416 - accuracy: 0.5561\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.2375 - accuracy: 0.6043\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 684us/step - loss: 0.2322 - accuracy: 0.6150\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.2268 - accuracy: 0.6150\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 711us/step - loss: 0.2209 - accuracy: 0.6578\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 680us/step - loss: 0.2133 - accuracy: 0.6791\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 668us/step - loss: 0.2048 - accuracy: 0.7005\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.1977 - accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 679us/step - loss: 0.1902 - accuracy: 0.7433\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 680us/step - loss: 0.1839 - accuracy: 0.7487\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 706us/step - loss: 0.1803 - accuracy: 0.7487\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.1745 - accuracy: 0.7754\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.1627 - accuracy: 0.7647\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.1572 - accuracy: 0.8021\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.1524 - accuracy: 0.8075\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 673us/step - loss: 0.1484 - accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.1459 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.1421 - accuracy: 0.7968\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.1422 - accuracy: 0.8235\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 641us/step - loss: 0.1366 - accuracy: 0.8075\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 665us/step - loss: 0.1358 - accuracy: 0.8235\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.1320 - accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.1328 - accuracy: 0.8342\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.1253 - accuracy: 0.8289\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.1241 - accuracy: 0.8396\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 645us/step - loss: 0.1214 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.1216 - accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.1181 - accuracy: 0.8396\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 703us/step - loss: 0.1200 - accuracy: 0.8289\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 707us/step - loss: 0.1214 - accuracy: 0.8342\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 627us/step - loss: 0.1163 - accuracy: 0.8396\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.1122 - accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1125 - accuracy: 0.8396\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1211 - accuracy: 0.8342\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 641us/step - loss: 0.1060 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.1079 - accuracy: 0.8610\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.1099 - accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.1045 - accuracy: 0.8610\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.1022 - accuracy: 0.8610\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 651us/step - loss: 0.1096 - accuracy: 0.8396\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 697us/step - loss: 0.1060 - accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 721us/step - loss: 0.1035 - accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 662us/step - loss: 0.1017 - accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 672us/step - loss: 0.0941 - accuracy: 0.8770\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 658us/step - loss: 0.1005 - accuracy: 0.8770\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 664us/step - loss: 0.0945 - accuracy: 0.8770\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 703us/step - loss: 0.0932 - accuracy: 0.8877\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 696us/step - loss: 0.0894 - accuracy: 0.9091\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.0933 - accuracy: 0.8717\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 658us/step - loss: 0.0919 - accuracy: 0.8663\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 636us/step - loss: 0.0924 - accuracy: 0.8877\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0904 - accuracy: 0.8717\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 695us/step - loss: 0.0911 - accuracy: 0.8717\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 687us/step - loss: 0.0865 - accuracy: 0.8930\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 688us/step - loss: 0.0861 - accuracy: 0.8930\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 686us/step - loss: 0.0803 - accuracy: 0.8930\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0911 - accuracy: 0.8877\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 702us/step - loss: 0.0847 - accuracy: 0.8770\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 679us/step - loss: 0.0811 - accuracy: 0.8984\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 661us/step - loss: 0.0812 - accuracy: 0.8770\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0864 - accuracy: 0.8824\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 714us/step - loss: 0.0800 - accuracy: 0.8877\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 700us/step - loss: 0.0761 - accuracy: 0.8984\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 678us/step - loss: 0.0778 - accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 710us/step - loss: 0.0746 - accuracy: 0.8930\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 706us/step - loss: 0.0720 - accuracy: 0.8984\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 709us/step - loss: 0.0750 - accuracy: 0.9037\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 709us/step - loss: 0.0753 - accuracy: 0.8930\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0713 - accuracy: 0.9144\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 651us/step - loss: 0.0688 - accuracy: 0.8930\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 673us/step - loss: 0.0699 - accuracy: 0.9251\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 755us/step - loss: 0.0677 - accuracy: 0.9251\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 692us/step - loss: 0.0657 - accuracy: 0.9305\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 647us/step - loss: 0.0683 - accuracy: 0.9037\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 694us/step - loss: 0.0647 - accuracy: 0.9091\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 689us/step - loss: 0.0662 - accuracy: 0.9144\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.0619 - accuracy: 0.9305\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.0618 - accuracy: 0.9198\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 651us/step - loss: 0.0617 - accuracy: 0.9358\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.0612 - accuracy: 0.9198\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 653us/step - loss: 0.0555 - accuracy: 0.9198\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 679us/step - loss: 0.0591 - accuracy: 0.9305\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 684us/step - loss: 0.0559 - accuracy: 0.9305\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0601 - accuracy: 0.9305\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 656us/step - loss: 0.0608 - accuracy: 0.9305\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 658us/step - loss: 0.0530 - accuracy: 0.9412\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0524 - accuracy: 0.9465\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 661us/step - loss: 0.0564 - accuracy: 0.9412\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.0509 - accuracy: 0.9251\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 693us/step - loss: 0.0506 - accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 694us/step - loss: 0.0494 - accuracy: 0.9412\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0487 - accuracy: 0.9465\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 828us/step - loss: 0.0517 - accuracy: 0.9198\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0514 - accuracy: 0.9519\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.0501 - accuracy: 0.9465\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.0494 - accuracy: 0.9412\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 653us/step - loss: 0.0457 - accuracy: 0.9572\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 679us/step - loss: 0.0445 - accuracy: 0.9572\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0411 - accuracy: 0.9572\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF1A1DB798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0825 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.2504 - accuracy: 0.5241\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.2449 - accuracy: 0.5348\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.2389 - accuracy: 0.6417\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.2316 - accuracy: 0.6631\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.2230 - accuracy: 0.6791\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.2113 - accuracy: 0.6791\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 556us/step - loss: 0.2015 - accuracy: 0.7166\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 569us/step - loss: 0.1878 - accuracy: 0.7380\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 557us/step - loss: 0.1788 - accuracy: 0.7487\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 567us/step - loss: 0.1718 - accuracy: 0.7701\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 611us/step - loss: 0.1650 - accuracy: 0.7701\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.1655 - accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.1610 - accuracy: 0.7807\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 585us/step - loss: 0.1508 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 618us/step - loss: 0.1467 - accuracy: 0.8021\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.1431 - accuracy: 0.8021\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 611us/step - loss: 0.1435 - accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 561us/step - loss: 0.1396 - accuracy: 0.8075\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 560us/step - loss: 0.1376 - accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 526us/step - loss: 0.1343 - accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 549us/step - loss: 0.1337 - accuracy: 0.8021\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 523us/step - loss: 0.1301 - accuracy: 0.8235\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 705us/step - loss: 0.1262 - accuracy: 0.8289\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.1296 - accuracy: 0.8075\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.1270 - accuracy: 0.8235\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.1216 - accuracy: 0.8610\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 669us/step - loss: 0.1197 - accuracy: 0.8396\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.1194 - accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 638us/step - loss: 0.1198 - accuracy: 0.8449\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 1.00 - 0s 651us/step - loss: 0.1168 - accuracy: 0.8235\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 635us/step - loss: 0.1168 - accuracy: 0.8396\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 699us/step - loss: 0.1101 - accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 668us/step - loss: 0.1107 - accuracy: 0.8610\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.1086 - accuracy: 0.8610\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.1105 - accuracy: 0.8663\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 720us/step - loss: 0.1034 - accuracy: 0.8877\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 668us/step - loss: 0.1076 - accuracy: 0.8449\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 632us/step - loss: 0.1037 - accuracy: 0.8770\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.1010 - accuracy: 0.8824\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 622us/step - loss: 0.0964 - accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 676us/step - loss: 0.1068 - accuracy: 0.8556\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.0978 - accuracy: 0.8824\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0976 - accuracy: 0.8877\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 672us/step - loss: 0.0993 - accuracy: 0.8717\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 659us/step - loss: 0.0952 - accuracy: 0.8877\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.0978 - accuracy: 0.8770\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 663us/step - loss: 0.0970 - accuracy: 0.8877\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0895 - accuracy: 0.8984\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 654us/step - loss: 0.0881 - accuracy: 0.8984\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0885 - accuracy: 0.8770\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 680us/step - loss: 0.0880 - accuracy: 0.8877\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 678us/step - loss: 0.0851 - accuracy: 0.9198\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0844 - accuracy: 0.9037\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0874 - accuracy: 0.8984\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 642us/step - loss: 0.0817 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 669us/step - loss: 0.0817 - accuracy: 0.9144\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 690us/step - loss: 0.0784 - accuracy: 0.9037\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 687us/step - loss: 0.0817 - accuracy: 0.9037\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0810 - accuracy: 0.8930\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0824 - accuracy: 0.9037\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.0789 - accuracy: 0.9037\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 651us/step - loss: 0.0806 - accuracy: 0.9144\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 697us/step - loss: 0.0780 - accuracy: 0.9144\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 715us/step - loss: 0.0731 - accuracy: 0.9198\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0706 - accuracy: 0.9251\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 684us/step - loss: 0.0690 - accuracy: 0.9144\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 678us/step - loss: 0.0763 - accuracy: 0.9198\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 671us/step - loss: 0.0725 - accuracy: 0.9198\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.0681 - accuracy: 0.9305\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0834 - accuracy: 0.8610\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.0669 - accuracy: 0.9305\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 715us/step - loss: 0.0653 - accuracy: 0.9305\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 670us/step - loss: 0.0637 - accuracy: 0.9251\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 646us/step - loss: 0.0641 - accuracy: 0.9198\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 704us/step - loss: 0.0623 - accuracy: 0.9251\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.0636 - accuracy: 0.9251\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.0645 - accuracy: 0.9305\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 666us/step - loss: 0.0605 - accuracy: 0.9305\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 706us/step - loss: 0.0595 - accuracy: 0.9358\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.0573 - accuracy: 0.9358\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.0593 - accuracy: 0.9305\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 683us/step - loss: 0.0581 - accuracy: 0.9305\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 704us/step - loss: 0.0551 - accuracy: 0.9358\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 712us/step - loss: 0.0550 - accuracy: 0.9305\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 675us/step - loss: 0.0553 - accuracy: 0.9358\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0581 - accuracy: 0.9358\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 690us/step - loss: 0.0541 - accuracy: 0.9358\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 652us/step - loss: 0.0506 - accuracy: 0.9519\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 710us/step - loss: 0.0567 - accuracy: 0.9465\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.0526 - accuracy: 0.9305\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 710us/step - loss: 0.0511 - accuracy: 0.9412\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 673us/step - loss: 0.0552 - accuracy: 0.9358\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 657us/step - loss: 0.0506 - accuracy: 0.9572\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0483 - accuracy: 0.9465\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 682us/step - loss: 0.0481 - accuracy: 0.9519\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 667us/step - loss: 0.0471 - accuracy: 0.9412\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 674us/step - loss: 0.0476 - accuracy: 0.9572\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 650us/step - loss: 0.0465 - accuracy: 0.9412\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 681us/step - loss: 0.0449 - accuracy: 0.9572\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 679us/step - loss: 0.0477 - accuracy: 0.9626\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF15EE8A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1376 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.2380 - accuracy: 0.6064\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 572us/step - loss: 0.2274 - accuracy: 0.6649\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.2211 - accuracy: 0.6543\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.2116 - accuracy: 0.7234\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.2043 - accuracy: 0.7181\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.1962 - accuracy: 0.7287\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1842 - accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.1766 - accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.1686 - accuracy: 0.7766\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.1596 - accuracy: 0.7819\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 626us/step - loss: 0.1595 - accuracy: 0.7872\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 640us/step - loss: 0.1526 - accuracy: 0.7979\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.1455 - accuracy: 0.8351\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.1410 - accuracy: 0.8085\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.1399 - accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 590us/step - loss: 0.1365 - accuracy: 0.8245\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.1362 - accuracy: 0.8032\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.1381 - accuracy: 0.8032\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.1282 - accuracy: 0.8511\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.1273 - accuracy: 0.8511\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 582us/step - loss: 0.1243 - accuracy: 0.8191\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 649us/step - loss: 0.1160 - accuracy: 0.8457\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.1157 - accuracy: 0.8564\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 539us/step - loss: 0.1138 - accuracy: 0.8511\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.1101 - accuracy: 0.8723\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.1082 - accuracy: 0.8723\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 565us/step - loss: 0.1089 - accuracy: 0.8723\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.1050 - accuracy: 0.8564\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 623us/step - loss: 0.1057 - accuracy: 0.8564\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 605us/step - loss: 0.1076 - accuracy: 0.8830\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 592us/step - loss: 0.1034 - accuracy: 0.8670\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.1005 - accuracy: 0.8670\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.0931 - accuracy: 0.8883\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 632us/step - loss: 0.0928 - accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.0956 - accuracy: 0.8777\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.0925 - accuracy: 0.8989\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 622us/step - loss: 0.0862 - accuracy: 0.8989\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0989 - accuracy: 0.8617\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 625us/step - loss: 0.0840 - accuracy: 0.8989\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 586us/step - loss: 0.0835 - accuracy: 0.9149\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.0819 - accuracy: 0.9096\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0848 - accuracy: 0.8989\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 633us/step - loss: 0.0790 - accuracy: 0.9202\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0762 - accuracy: 0.9255\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.0787 - accuracy: 0.8936\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0763 - accuracy: 0.9149\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0743 - accuracy: 0.9202\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.0721 - accuracy: 0.9255\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.0710 - accuracy: 0.9149\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 634us/step - loss: 0.0683 - accuracy: 0.9255\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.0654 - accuracy: 0.9415\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0686 - accuracy: 0.9362\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0778 - accuracy: 0.8989\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 591us/step - loss: 0.0644 - accuracy: 0.9255\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.0631 - accuracy: 0.9309\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 610us/step - loss: 0.0636 - accuracy: 0.9415\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.0589 - accuracy: 0.9362\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 594us/step - loss: 0.0588 - accuracy: 0.9362\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0603 - accuracy: 0.9309\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0578 - accuracy: 0.9415\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 575us/step - loss: 0.0548 - accuracy: 0.9309\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0543 - accuracy: 0.9415\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.0528 - accuracy: 0.9468\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 597us/step - loss: 0.0531 - accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0536 - accuracy: 0.9415\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.0499 - accuracy: 0.9521\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.0534 - accuracy: 0.9521\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 620us/step - loss: 0.0474 - accuracy: 0.9521\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.0458 - accuracy: 0.9574\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0508 - accuracy: 0.9362\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 591us/step - loss: 0.0431 - accuracy: 0.9628\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 622us/step - loss: 0.0472 - accuracy: 0.9415\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 624us/step - loss: 0.0462 - accuracy: 0.9574\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0413 - accuracy: 0.9521\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0398 - accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 570us/step - loss: 0.0403 - accuracy: 0.9734\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0384 - accuracy: 0.9734\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.0353 - accuracy: 0.9681\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 587us/step - loss: 0.0362 - accuracy: 0.9734\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 625us/step - loss: 0.0347 - accuracy: 0.9734\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0336 - accuracy: 0.9787\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0324 - accuracy: 0.9787\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 632us/step - loss: 0.0323 - accuracy: 0.9681\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 636us/step - loss: 0.0313 - accuracy: 0.9734\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0317 - accuracy: 0.9734\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 629us/step - loss: 0.0296 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.0261 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 649us/step - loss: 0.0273 - accuracy: 0.9734\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 668us/step - loss: 0.0284 - accuracy: 0.9787\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0240 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 700us/step - loss: 0.0229 - accuracy: 0.9894\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 651us/step - loss: 0.0239 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 642us/step - loss: 0.0231 - accuracy: 0.9840\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 656us/step - loss: 0.0213 - accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 677us/step - loss: 0.0239 - accuracy: 0.9787\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 655us/step - loss: 0.0209 - accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 659us/step - loss: 0.0185 - accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 660us/step - loss: 0.0181 - accuracy: 0.9894\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 686us/step - loss: 0.0171 - accuracy: 0.9894\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 672us/step - loss: 0.0146 - accuracy: 0.9947\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF175B13A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0700 - accuracy: 0.9000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 607us/step - loss: 0.2507 - accuracy: 0.5213\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.2376 - accuracy: 0.6064\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.2302 - accuracy: 0.6011\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 574us/step - loss: 0.2174 - accuracy: 0.7340\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 587us/step - loss: 0.2084 - accuracy: 0.7181\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 537us/step - loss: 0.1999 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 587us/step - loss: 0.1880 - accuracy: 0.7553\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.1808 - accuracy: 0.7660\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 623us/step - loss: 0.1748 - accuracy: 0.7606\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 504us/step - loss: 0.1676 - accuracy: 0.7979\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.1663 - accuracy: 0.7606\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.1585 - accuracy: 0.7819\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.1536 - accuracy: 0.8138\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 527us/step - loss: 0.1513 - accuracy: 0.7872\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 561us/step - loss: 0.1534 - accuracy: 0.7660\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 630us/step - loss: 0.1415 - accuracy: 0.8138\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 589us/step - loss: 0.1467 - accuracy: 0.7872\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1403 - accuracy: 0.8138\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.1335 - accuracy: 0.8245\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 628us/step - loss: 0.1342 - accuracy: 0.8298\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 571us/step - loss: 0.1331 - accuracy: 0.8138\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 637us/step - loss: 0.1255 - accuracy: 0.8298\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 607us/step - loss: 0.1191 - accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.1195 - accuracy: 0.8457\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 598us/step - loss: 0.1175 - accuracy: 0.8564\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.1160 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.1149 - accuracy: 0.8617\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 609us/step - loss: 0.1094 - accuracy: 0.8777\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 591us/step - loss: 0.1127 - accuracy: 0.8670\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.1124 - accuracy: 0.8723\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.1049 - accuracy: 0.8723\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 554us/step - loss: 0.1020 - accuracy: 0.8883\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 574us/step - loss: 0.1023 - accuracy: 0.8936\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 546us/step - loss: 0.1000 - accuracy: 0.8883\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 566us/step - loss: 0.1002 - accuracy: 0.8936\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0980 - accuracy: 0.8936\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 572us/step - loss: 0.0947 - accuracy: 0.9096\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 572us/step - loss: 0.0968 - accuracy: 0.8777\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 547us/step - loss: 0.0990 - accuracy: 0.8670\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 578us/step - loss: 0.0915 - accuracy: 0.9043\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0907 - accuracy: 0.8936\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0854 - accuracy: 0.9043\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0909 - accuracy: 0.8883\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 565us/step - loss: 0.0863 - accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0859 - accuracy: 0.9202\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0840 - accuracy: 0.8830\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0824 - accuracy: 0.9149\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 592us/step - loss: 0.0808 - accuracy: 0.9149\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 552us/step - loss: 0.0802 - accuracy: 0.9255\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 553us/step - loss: 0.0822 - accuracy: 0.9096\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 602us/step - loss: 0.0822 - accuracy: 0.8936\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.0825 - accuracy: 0.9096\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 611us/step - loss: 0.0759 - accuracy: 0.9096\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 599us/step - loss: 0.0753 - accuracy: 0.9202\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 607us/step - loss: 0.0766 - accuracy: 0.9202\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0728 - accuracy: 0.9202\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 631us/step - loss: 0.0724 - accuracy: 0.9202\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 613us/step - loss: 0.0715 - accuracy: 0.9202\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0733 - accuracy: 0.9149\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0718 - accuracy: 0.9096\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 604us/step - loss: 0.0699 - accuracy: 0.9149\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 610us/step - loss: 0.0722 - accuracy: 0.9149\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0697 - accuracy: 0.9202\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 616us/step - loss: 0.0685 - accuracy: 0.9309\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0656 - accuracy: 0.9255\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 590us/step - loss: 0.0653 - accuracy: 0.9202\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0640 - accuracy: 0.9202\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 580us/step - loss: 0.0622 - accuracy: 0.9362\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 612us/step - loss: 0.0672 - accuracy: 0.9309\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0637 - accuracy: 0.9255\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 600us/step - loss: 0.0625 - accuracy: 0.9255\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 595us/step - loss: 0.0629 - accuracy: 0.9255\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 621us/step - loss: 0.0610 - accuracy: 0.9362\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 567us/step - loss: 0.0558 - accuracy: 0.9468\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0569 - accuracy: 0.9309\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 570us/step - loss: 0.0599 - accuracy: 0.9362\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0553 - accuracy: 0.9415\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 601us/step - loss: 0.0577 - accuracy: 0.9309\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 589us/step - loss: 0.0564 - accuracy: 0.9362\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 575us/step - loss: 0.0530 - accuracy: 0.9309\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 625us/step - loss: 0.0500 - accuracy: 0.9574\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 615us/step - loss: 0.0533 - accuracy: 0.9309\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0492 - accuracy: 0.9415\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 560us/step - loss: 0.0484 - accuracy: 0.9415\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 593us/step - loss: 0.0482 - accuracy: 0.9468\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 603us/step - loss: 0.0474 - accuracy: 0.9628\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.0531 - accuracy: 0.9309\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0482 - accuracy: 0.9574\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 581us/step - loss: 0.0493 - accuracy: 0.9468\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 579us/step - loss: 0.0437 - accuracy: 0.9521\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.0479 - accuracy: 0.9521\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 592us/step - loss: 0.0473 - accuracy: 0.9468\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0475 - accuracy: 0.9521\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.0423 - accuracy: 0.9574\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0436 - accuracy: 0.9574\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 576us/step - loss: 0.0516 - accuracy: 0.9202\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 606us/step - loss: 0.0443 - accuracy: 0.9574\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 577us/step - loss: 0.0415 - accuracy: 0.9628\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 588us/step - loss: 0.0409 - accuracy: 0.9574\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 575us/step - loss: 0.0455 - accuracy: 0.9468\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001FF1A1DB828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1643 - accuracy: 0.7500\n",
      "\n",
      " 10 fold accuracy: ['0.7143', '0.8095', '0.7619', '0.9524', '0.8095', '0.8571', '0.8571', '0.8095', '0.9000', '0.7500']\n"
     ]
    }
   ],
   "source": [
    "accuracy=[]\n",
    "\n",
    "for train,test in skf.split(X,Y):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(24,input_dim=60,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    X_train=tf.convert_to_tensor(X[train],dtype=tf.float32)\n",
    "    Y_train=tf.convert_to_tensor(Y[train],dtype=tf.float32)\n",
    "    model.fit(X_train,Y_train,epochs=100,batch_size=5)\n",
    "    X_test=tf.convert_to_tensor(X[test],dtype=tf.float32)\n",
    "    Y_test=tf.convert_to_tensor(Y[test],dtype=tf.float32)\n",
    "    k_accuracy=\"%.4f\" %(model.evaluate(X_test,Y_test)[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "    \n",
    "print(\"\\n %.f fold accuracy:\" %n_fold,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
